## Financial Fraud Detection

### Overview

Electronic payment systems are targets for fraudulent activity.  Detecting suspicious transactions quickly is critical for limiting losses and maintaining customer trust.  This project leverages the *PaySim* dataset to build models that flag potentially fraudulent mobile money transactions.  The dataset is synthetic but realistic; it was generated by simulating transactions based on patterns observed in a real mobile money service provider【305747528437363†L46-L49】.

### Problem Statement

Financial institutions need automated systems to identify anomalies in large volumes of transactions.  The goal of this project is to train and evaluate machine learning models that distinguish between legitimate and fraudulent transactions using features such as transaction amount, type and origin/destination accounts.  Because fraud is rare compared with legitimate transactions, class imbalance and false positives are key challenges.

### Data Source

The PaySim simulator produces a dataset of mobile money transfers using aggregated, anonymised data from a real service provider【305747528437363†L46-L49】.  The simulation models interactions among clients, merchants and banks through various transaction types (e.g. cash in, cash out, debit, transfer and payment) and captures typical behaviours such as top‑ups, withdrawals and merchant payments【305747528437363†L121-L178】.  Each record includes the transaction amount, origin and destination balances, transaction type and a flag indicating whether it is fraudulent.

### Tools Used

- **Python** with `pandas` and `NumPy` for data processing.
- **Scikit‑learn** for model building and evaluation.
- **Imbalanced‑Learn** (`imblearn`) for handling class imbalance via SMOTE and undersampling.
- **Matplotlib** and **Seaborn** for visualisation.
- Optional: **XGBoost** for gradient boosting models.

### Business Value

Effective fraud detection models reduce monetary losses, improve customer confidence and help comply with regulatory requirements.  Automating detection enables real‑time monitoring and reduces the workload on human analysts.  Insights from the model (e.g. which transaction types or amounts are most risky) can inform policy changes and targeted investigations.

### Approach and Key Findings

1. **Data Loading** –  The PaySim CSV file is loaded into a DataFrame.  Data types are corrected, and irrelevant identifiers are removed.
2. **Exploratory Analysis** –  Transaction amounts and types are summarised.  Fraudulent transactions tend to have distinctive patterns, such as unusually high amounts or certain transaction types.
3. **Handling Class Imbalance** –  Since fraud cases constitute only a tiny fraction of the dataset, techniques like *Synthetic Minority Over‑sampling Technique* (SMOTE) and random undersampling are applied to balance the classes.
4. **Modelling** –  Two algorithms are trained:
   * *Random Forest* –  An ensemble of decision trees that handles non‑linear relationships and returns feature importance.
   * *XGBoost* –  A gradient boosting method that often achieves high predictive accuracy on tabular data.
5. **Evaluation** –  Models are assessed using metrics appropriate for imbalanced data, including ROC‑AUC, precision–recall curves and F1‑score.  Confusion matrices are also inspected to understand false positive and false negative rates.  Visualisations of these metrics are saved under `fraud-detection-finance/images`.
6. **Interpretation** –  Feature importance charts reveal which variables (e.g. transaction amount, balance difference, transaction type) contribute most to detecting fraud.

### Visualisations

- Distribution plots of transaction amounts for legitimate vs. fraudulent transactions
- Confusion matrices and ROC‑AUC curves for each model
- Precision–recall curves to highlight performance on the minority class
- Bar chart of feature importances

The final analysis demonstrates that ensemble models, combined with appropriate resampling, can detect a high proportion of fraudulent transactions with manageable false positive rates.  A dashboard could be built to monitor live risk scores and highlight patterns of concern.
